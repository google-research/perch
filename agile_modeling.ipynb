{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEoybFElAON3"
   },
   "source": [
    "# Agile Modeling for Bioacoustics.\n",
    "\n",
    "This notebook provides a workflow for creating custom classifiers for target signals, by first **searching** for training data, and then engaging in an **active learning** loop.\n",
    "\n",
    "We assume that embeddings have been pre-computed using `embed.ipynb`.\n",
    "\n",
    "# ATTENTION: \n",
    "\n",
    "There is a new version of this workflow avialable [here](https://github.com/google-research/perch-hoplite/blob/main/perch_hoplite/agile/1_embed_audio_v2.ipynb), in the new [Perch-Hoplite](https://github.com/google-research/perch-hoplite/blob/main/perch_hoplite) respository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gntw2Wq9Atpp"
   },
   "source": [
    "## Configuration and Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "coetZk9xAjCs"
   },
   "outputs": [],
   "source": [
    "#@title Installation. { vertical-output: true }\n",
    "#@markdown Run this notebook in Google Colab by following [this link](https://colab.research.google.com/github/google-research/perch/blob/main/agile_modeling.ipynb).\n",
    "#@markdown\n",
    "#@markdown Run this cell to install the project dependencies.\n",
    "%pip install git+https://github.com/google-research/perch.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "58HLTIdcAzte"
   },
   "outputs": [],
   "source": [
    " #@title Imports. { vertical-output: true }\n",
    "\n",
    "import collections\n",
    "from etils import epath\n",
    "from ml_collections import config_dict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from chirp.inference import colab_utils\n",
    "colab_utils.initialize(use_tf_gpu=True, disable_warnings=True)\n",
    "\n",
    "from chirp import audio_utils\n",
    "from chirp.inference import baw_utils\n",
    "from chirp.inference import tf_examples\n",
    "from chirp.models import metrics\n",
    "from perch_hoplite.taxonomy import namespace\n",
    "from chirp.inference.search import bootstrap\n",
    "from chirp.inference.search import search\n",
    "from chirp.inference.search import display\n",
    "from chirp.inference.classify import classify\n",
    "from chirp.inference.classify import data_lib\n",
    "from perch_hoplite.zoo import model_configs\n",
    "from perch_hoplite.zoo import zoo_interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "_fMOBVK9A_O1"
   },
   "outputs": [],
   "source": [
    "#@title Basic Configuration. { vertical-output: true }\n",
    "\n",
    "#@markdown Choose what data to work with.\n",
    "#@markdown * For local data (most cases), choose 'filesystem'.\n",
    "#@markdown * For Australian Acoustic Observatory, select 'a2o'.\n",
    "#@markdown This will cause many options (like model_choice) to be overridden.\n",
    "#@markdown Note that you will need an Authentication Token from:\n",
    "#@markdown https://data.acousticobservatory.org/my_account\n",
    "data_source = 'filesystem' #@param['filesystem', 'a2o']\n",
    "baw_auth_token = '' #@param {type:'string'}\n",
    "\n",
    "#@markdown Set the base directory for the project.\n",
    "working_dir = '/tmp/agile'  #@param {type:'string'}\n",
    "\n",
    "#@markdown Set the embedding and labeled data directories.\n",
    "labeled_data_path = epath.Path(working_dir) / 'labeled'\n",
    "custom_classifier_path = epath.Path(working_dir) / 'custom_classifier'\n",
    "\n",
    "#@markdown The embeddings_path should be detected automatically, but can be\n",
    "#@markdown overridden.\n",
    "embeddings_path = ''\n",
    "\n",
    "#@markdown OPTIONAL: Set up separation model.\n",
    "separation_model_key = 'separator_model_tf'  #@param {type:'string'}\n",
    "separation_model_path = ''  #@param {type:'string'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "2c4gJ6S2ETKu"
   },
   "outputs": [],
   "source": [
    "#@title Load Project State and Models. { vertical-output: true }\n",
    "\n",
    "if data_source == 'a2o':\n",
    "  embedding_config = baw_utils.get_a2o_embeddings_config()\n",
    "  bootstrap_config = bootstrap.BootstrapConfig.load_from_embedding_config(\n",
    "      embedding_config=embedding_config,\n",
    "      annotated_path=labeled_data_path,\n",
    "      embeddings_glob = '*/embeddings-*')\n",
    "  embeddings_path = embedding_config.output_dir\n",
    "elif (embeddings_path\n",
    "      or (epath.Path(working_dir) / 'embeddings/config.json').exists()):\n",
    "  if not embeddings_path:\n",
    "    # Use the default embeddings path, as it seems we found a config there.\n",
    "    embeddings_path = epath.Path(working_dir) / 'embeddings'\n",
    "  # Get relevant info from the embedding configuration.\n",
    "  bootstrap_config = bootstrap.BootstrapConfig.load_from_embedding_path(\n",
    "      embeddings_path=embeddings_path,\n",
    "      annotated_path=labeled_data_path)\n",
    "  if (bootstrap_config.model_key == 'separate_embed_model'\n",
    "      and not separation_model_path.strip()):\n",
    "    separation_model_key = 'separator_model_tf'\n",
    "    separation_model_path = bootstrap_config.model_config.separator_model_tf_config.model_path\n",
    "  baw_auth_token = ''\n",
    "else:\n",
    "  raise ValueError('No embedding configuration found.')\n",
    "\n",
    "project_state = bootstrap.BootstrapState(\n",
    "    bootstrap_config, baw_auth_token=baw_auth_token)\n",
    "\n",
    "# Load separation model.\n",
    "if separation_model_path:\n",
    "  separation_config = config_dict.ConfigDict({\n",
    "      'model_path': separation_model_path,\n",
    "      'frame_size': 32000,\n",
    "      'sample_rate': 32000,\n",
    "  })\n",
    "  separator = model_configs.MODEL_CLASS_MAP[\n",
    "      separation_model_key].from_config(separation_config)\n",
    "  print('Loaded separator model at {}'.format(separation_model_path))\n",
    "else:\n",
    "  print('No separation model loaded.')\n",
    "  separator = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0p0qkxcFSG0"
   },
   "source": [
    "## Search Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eML2kUhuGfZQ"
   },
   "source": [
    "### Query Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "xc1ExwK2GbQx"
   },
   "outputs": [],
   "source": [
    "#@title Load query audio. { vertical-output: true }\n",
    "\n",
    "#@markdown You may specify:\n",
    "#@markdown * an audio filepath (like `/home/me/audio/example.wav`),\n",
    "#@markdown * a Xeno-Canto id (like `xc12345`), or\n",
    "#@markdown * an audio file URL (like\n",
    "#@markdown https://upload.wikimedia.org/wikipedia/commons/7/7c/Turdus_merula_2.ogg).\n",
    "audio_path = 'xc692557'  #@param\n",
    "#@markdown Choose the start time for the audio window within the file.\n",
    "#@markdown We will focus on the model's `window_size_s` seconds of audio,\n",
    "#@markdown starting from `start_s` seconds into the file.\n",
    "start_s = 0  #@param\n",
    "\n",
    "window_s = bootstrap_config.model_config['window_size_s']\n",
    "sample_rate = bootstrap_config.model_config['sample_rate']\n",
    "audio = audio_utils.load_audio(audio_path, sample_rate)\n",
    "\n",
    "# Display the full file.\n",
    "display.plot_audio_melspec(audio, sample_rate)\n",
    "\n",
    "# Display the selected window.\n",
    "print('-' * 80)\n",
    "print('Selected audio window:')\n",
    "st = int(start_s * sample_rate)\n",
    "end = int(st + window_s * sample_rate)\n",
    "if end > audio.shape[0]:\n",
    "  end = audio.shape[0]\n",
    "  st = max([0, int(end - window_s * sample_rate)])\n",
    "audio_window = audio[st:end]\n",
    "display.plot_audio_melspec(audio_window, sample_rate)\n",
    "\n",
    "query_audio = audio_window\n",
    "sep_outputs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "uELuAcwjGj4h"
   },
   "outputs": [],
   "source": [
    "#@title Separate the target audio window { vertical-output: true }\n",
    "\n",
    "if separator is not None:\n",
    "  sep_outputs = separator.embed(audio_window)\n",
    "\n",
    "  for c in range(sep_outputs.separated_audio.shape[0]):\n",
    "    print(f'Channel {c}')\n",
    "    display.plot_audio_melspec(sep_outputs.separated_audio[c, :], sample_rate)\n",
    "    print('-' * 80)\n",
    "else:\n",
    "  sep_outputs = None\n",
    "  print('No separation model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "atpdag0FGkud"
   },
   "outputs": [],
   "source": [
    "#@title Select the query channel. { vertical-output: true }\n",
    "\n",
    "#@markdown Choose a name for the class.\n",
    "query_label = 'my_class'  #@param\n",
    "#@markdown If you have applied separation, choose a channel.\n",
    "#@markdown Ignored if no separation model is being used.\n",
    "query_channel = 0  #@param\n",
    "\n",
    "if query_channel < 0 or sep_outputs is None:\n",
    "  query_audio = audio_window\n",
    "else:\n",
    "  query_audio = sep_outputs.separated_audio[query_channel].copy()\n",
    "\n",
    "display.plot_audio_melspec(query_audio, sample_rate)\n",
    "\n",
    "outputs = project_state.embedding_model.embed(query_audio)\n",
    "query = outputs.pooled_embeddings('first', 'first')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_Sx9wlJGo9y"
   },
   "source": [
    "### Execute Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "tOV_G29mGm_Z"
   },
   "outputs": [],
   "source": [
    "#@title Run Top-K Search. { vertical-output: true }\n",
    "\n",
    "#@markdown Number of search results to capture.\n",
    "top_k = 50  #@param\n",
    "\n",
    "#@markdown Target distance for search results.\n",
    "#@markdown This lets us try to hone in on a 'classifier boundary' instead of\n",
    "#@markdown just looking at the closest matches.\n",
    "#@markdown Set to 'None' for raw 'best results' search.\n",
    "target_score = None  #@param\n",
    "\n",
    "#@markdown Maximimum Inner-Product (mip) generally gives best results.\n",
    "metric = 'mip'  #@param['euclidean', 'mip', 'cosine']\n",
    "\n",
    "#@markdown If True, produce a fully-random sample of data, ignoring similarity.\n",
    "random_sample = False  #@param\n",
    "\n",
    "ds = project_state.create_embeddings_dataset(shuffle_files=True)\n",
    "results, all_scores = search.search_embeddings_parallel(\n",
    "    ds, query,\n",
    "    hop_size_s=bootstrap_config.embedding_hop_size_s,\n",
    "    top_k=top_k, target_score=target_score, score_fn=metric,\n",
    "    random_sample=random_sample)\n",
    "\n",
    "# Plot histogram of distances\n",
    "ys, _, _ = plt.hist(all_scores, bins=128, density=True)\n",
    "hit_scores = [r.score for r in results.search_results]\n",
    "plt.scatter(hit_scores, np.zeros_like(hit_scores), marker='|',\n",
    "            color='r', alpha=0.5)\n",
    "\n",
    "plt.xlabel(metric)\n",
    "plt.ylabel('density')\n",
    "if target_score is not None:\n",
    "  plt.plot([target_score, target_score], [0.0, np.max(ys)], 'r:')\n",
    "  # Compute the proportion of scores < target_score\n",
    "  hit_percentage = (all_scores < target_score).mean()\n",
    "  print(f'score < target_score percentage : {hit_percentage:5.3f}')\n",
    "min_score = np.min(all_scores)\n",
    "plt.plot([min_score, min_score], [0.0, np.max(ys)], 'g:')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "a8SYu-M2GsZx"
   },
   "outputs": [],
   "source": [
    "#@title Display results. { vertical-output: true }\n",
    "\n",
    "samples_per_page = 25\n",
    "page_state = display.PageState(\n",
    "    np.ceil(len(results.search_results) / samples_per_page))\n",
    "\n",
    "display.display_paged_results(\n",
    "    results, page_state, samples_per_page,\n",
    "    project_state=project_state,\n",
    "    embedding_sample_rate=project_state.embedding_model.sample_rate,\n",
    "    exclusive_labels=False,\n",
    "    checkbox_labels=[query_label, 'unknown'],\n",
    "    max_workers=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-wi-TOGDGvh5"
   },
   "outputs": [],
   "source": [
    "#@title Write annotated examples. { vertical-output: true }\n",
    "\n",
    "results.write_labeled_data(bootstrap_config.annotated_path,\n",
    "                           project_state.embedding_model.sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbZkOXncFYKm"
   },
   "source": [
    "## Active Learning for a Target Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "NcLdypLeHmss"
   },
   "outputs": [],
   "source": [
    "# @title Load+Embed the Labeled Dataset. { vertical-output: true }\n",
    "\n",
    "#@markdown Time-pooling strategy for audio longer than the model's window size.\n",
    "time_pooling = 'mean'  # @param\n",
    "\n",
    "merged = data_lib.MergedDataset.from_folder_of_folders(\n",
    "    base_dir=labeled_data_path,\n",
    "    embedding_model=project_state.embedding_model,\n",
    "    time_pooling=time_pooling,\n",
    "    load_audio=False,\n",
    "    target_sample_rate=-2,\n",
    "    audio_file_pattern='*',\n",
    "    embedding_config_hash=bootstrap_config.embedding_config_hash(),\n",
    ")\n",
    "\n",
    "# Label distribution\n",
    "lbl_counts = np.sum(merged.data['label_hot'], axis=0)\n",
    "print('num classes :', (lbl_counts > 0).sum())\n",
    "print('mean ex / class :', lbl_counts.sum() / (lbl_counts > 0).sum())\n",
    "print('min ex / class :', (lbl_counts + (lbl_counts == 0) * 1e6).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "7mY5rIiDHoE0"
   },
   "outputs": [],
   "source": [
    "#@title Train small model over embeddings. { vertical-output: true }\n",
    "\n",
    "#@markdown Number of random training examples to choose form each class.\n",
    "#@markdown Set exactly one of `train_ratio` and `train_examples_per_class`.\n",
    "train_ratio = 0.9  #@param\n",
    "train_examples_per_class = None  #@param\n",
    "\n",
    "#@markdown Number of random re-trainings. Allows judging model stability.\n",
    "num_seeds = 3  #@param\n",
    "\n",
    "# Classifier training hyperparams.\n",
    "# These should be good defaults.\n",
    "batch_size = 32\n",
    "num_epochs = 128\n",
    "num_hiddens = -1\n",
    "learning_rate = 1e-3\n",
    "\n",
    "metrics = collections.defaultdict(list)\n",
    "for seed in tqdm.tqdm(range(num_seeds)):\n",
    "  if num_hiddens > 0:\n",
    "    model = classify.get_two_layer_model(\n",
    "        num_hiddens, merged.embedding_dim, merged.num_classes)\n",
    "  else:\n",
    "    model = classify.get_linear_model(\n",
    "        merged.embedding_dim, merged.num_classes)\n",
    "  run_metrics = classify.train_embedding_model(\n",
    "      model, merged, train_ratio, train_examples_per_class,\n",
    "      num_epochs, seed, batch_size, learning_rate)\n",
    "  metrics['acc'].append(run_metrics.top1_accuracy)\n",
    "  metrics['auc_roc'].append(run_metrics.auc_roc)\n",
    "  metrics['cmap'].append(run_metrics.cmap_value)\n",
    "  metrics['maps'].append(run_metrics.class_maps)\n",
    "  metrics['test_logits'].append(run_metrics.test_logits)\n",
    "\n",
    "mean_acc = np.mean(metrics['acc'])\n",
    "mean_auc = np.mean(metrics['auc_roc'])\n",
    "mean_cmap = np.mean(metrics['cmap'])\n",
    "# Merge the test_logits into a single array.\n",
    "test_logits = {\n",
    "    k: np.concatenate([logits[k] for logits in metrics['test_logits']])\n",
    "    for k in metrics['test_logits'][0].keys()\n",
    "}\n",
    "\n",
    "print(f'acc:{mean_acc:5.2f}, auc_roc:{mean_auc:5.2f}, cmap:{mean_cmap:5.2f}')\n",
    "for lbl, auc in zip(merged.labels, run_metrics.class_maps):\n",
    "  if np.isnan(auc):\n",
    "    continue\n",
    "  print(f'\\n{lbl:8s}, auc_roc:{auc:5.2f}')\n",
    "  colab_utils.prstats(f'test_logits({lbl})',\n",
    "                      test_logits[merged.labels.index(lbl)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-0Kg43YhH0p3"
   },
   "outputs": [],
   "source": [
    "#@title Run model on target unlabeled data. { vertical-output: true }\n",
    "\n",
    "#@markdown Choose the target class to work with.\n",
    "target_class = 'my_class'  #@param\n",
    "#@markdown Choose a target logit; will display results close to the target.\n",
    "#@markdown Set to None to get the highest-logit examples.\n",
    "target_logit = 0.0  #@param\n",
    "#@markdown Number of results to display.\n",
    "num_results = 50  #@param\n",
    "\n",
    "embeddings_ds = project_state.create_embeddings_dataset(\n",
    "    shuffle_files=True)\n",
    "target_class_idx = merged.labels.index(target_class)\n",
    "results, all_logits = search.classifer_search_embeddings_parallel(\n",
    "    embeddings_classifier=model,\n",
    "    target_index=target_class_idx,\n",
    "    embeddings_dataset=embeddings_ds,\n",
    "    hop_size_s=bootstrap_config.embedding_hop_size_s,\n",
    "    target_score=target_logit,\n",
    "    top_k=num_results\n",
    ")\n",
    "\n",
    "# Plot the histogram of logits.\n",
    "ys, _, _ = plt.hist(all_logits, bins=128, density=True)\n",
    "plt.xlabel(f'{target_class} logit')\n",
    "plt.ylabel('density')\n",
    "# plt.yscale('log')\n",
    "plt.plot([target_logit, target_logit], [0.0, np.max(ys)], 'r:')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "gHI2WJwPH2Wy"
   },
   "outputs": [],
   "source": [
    "#@title Display results for the target label. { vertical-output: true }\n",
    "\n",
    "display_labels = merged.labels\n",
    "\n",
    "#@markdown Specify any extra labels you would like displayed.\n",
    "extra_labels = []  #@param\n",
    "for label in extra_labels:\n",
    "  if label not in merged.labels:\n",
    "    display_labels += (label,)\n",
    "if 'unknown' not in merged.labels:\n",
    "  display_labels += ('unknown',)\n",
    "\n",
    "samples_per_page = 25\n",
    "page_state = display.PageState(\n",
    "    np.ceil(len(results.search_results) / samples_per_page))\n",
    "\n",
    "display.display_paged_results(\n",
    "    results, page_state, samples_per_page,\n",
    "    project_state=project_state,\n",
    "    embedding_sample_rate=project_state.embedding_model.sample_rate,\n",
    "    exclusive_labels=False,\n",
    "    checkbox_labels=display_labels,\n",
    "    max_workers=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "mDCcKfBGH4b_"
   },
   "outputs": [],
   "source": [
    "#@title Add selected results to the labeled data. { vertical-output: true }\n",
    "\n",
    "results.write_labeled_data(\n",
    "    bootstrap_config.annotated_path,\n",
    "    project_state.embedding_model.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ZxasEcnhd7kP"
   },
   "outputs": [],
   "source": [
    "#@title Save the Custom Classifier. { vertical-output: true }\n",
    "\n",
    "wrapped_model = zoo_interface.LogitsOutputHead(\n",
    "    model_path=custom_classifier_path.as_posix(),\n",
    "    logits_key='logits',\n",
    "    logits_model=model,\n",
    "    class_list=namespace.ClassList('custom', merged.labels),\n",
    ")\n",
    "wrapped_model.save_model(\n",
    "    custom_classifier_path,\n",
    "    embeddings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNw_uivxIJda"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "XdpUiaYiIMIp"
   },
   "outputs": [],
   "source": [
    "#@title Write classifier inference CSV. { vertical-output: true }\n",
    "\n",
    "#@markdown This cell writes detections (locations of audio windows where\n",
    "#@markdown the logit was greater than a threshold) to a CSV file.\n",
    "\n",
    "output_filepath = epath.Path(working_dir) / 'inference.csv'  #@param\n",
    "\n",
    "#@markdown Set the default detection thresholds, used for all classes.\n",
    "#@markdown To set per-class detection thresholds, modify the code below.\n",
    "#@markdown Keep in mind that thresholds are on the logit scale, so 0.0\n",
    "#@markdown corresponds to a 50% model confidence.\n",
    "default_threshold = 0.0  #@param\n",
    "if default_threshold is None:\n",
    "  # In this case, all logits are written. This can lead to very large CSV files.\n",
    "  class_thresholds = None\n",
    "else:\n",
    "  class_thresholds = collections.defaultdict(lambda: default_threshold)\n",
    "  # Add any per-class thresholds here.\n",
    "  class_thresholds['my_class'] = 1.0\n",
    "\n",
    "#@markdown Classes to ignore when counting detections.\n",
    "exclude_classes = ['unknown']  #@param\n",
    "\n",
    "#@markdown The `include_classes` list is ignored if empty.\n",
    "#@markdown If non-empty, only scores for these classes will be written.\n",
    "include_classes = []  #@param\n",
    "\n",
    "embeddings_ds = project_state.create_embeddings_dataset(\n",
    "    shuffle_files=True)\n",
    "classify.write_inference_csv(\n",
    "    embeddings_ds=embeddings_ds,\n",
    "    model=model,\n",
    "    labels=merged.labels,\n",
    "    output_filepath=output_filepath,\n",
    "    threshold=class_thresholds,\n",
    "    embedding_hop_size_s=bootstrap_config.embedding_hop_size_s,\n",
    "    include_classes=include_classes,\n",
    "    exclude_classes=exclude_classes)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
