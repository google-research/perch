{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5dNnKRjJlGg"
      },
      "source": [
        "# Embed Audio\n",
        "\n",
        "This notebook provides a single-machine workflow for embedding raw audio files.\n",
        "This notebookis ideal for a single machine with a GPU for accelarated embedding.\n",
        "\n",
        "For parallelized workflow, try `inference/embed.py`, which uses a Beam pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnB90FczJkkZ"
      },
      "outputs": [],
      "source": [
        "#@title Imports. { vertical-output: true }\n",
        "\n",
        "# Global imports\n",
        "from etils import epath\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tqdm\n",
        "from chirp.inference import colab_utils\n",
        "colab_utils.initialize(use_tf_gpu=True, disable_warnings=True)\n",
        "\n",
        "from chirp import audio_utils\n",
        "from chirp import config_utils\n",
        "from chirp.configs import config_globals\n",
        "from chirp.inference import embed_lib\n",
        "from chirp.inference import tf_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSlVLs_WKOLo"
      },
      "outputs": [],
      "source": [
        "#@title Configuration. { vertical-output: true }\n",
        "\n",
        "# Name of base configuration file in `chirp/inference/configs`\n",
        "config_key = 'raw_soundscapes'  #@param\n",
        "config = embed_lib.get_config(config_key)\n",
        "config = config_utils.parse_config(config, config_globals.get_globals())\n",
        "\n",
        "# Here we adjust the input and output targets.\n",
        "config.output_dir = ''  #@param\n",
        "config.source_file_patterns = ['']  #@param\n",
        "\n",
        "# Define the model\n",
        "model_choice = 'perch'\n",
        "# For Perch, the directory containing the model.\n",
        "# For BirdNET, point to the specific tflite file.\n",
        "model_path = ''  #@param\n",
        "config.embed_fn_config.model_config.model_path = model_path\n",
        "if model_choice == 'perch':\n",
        "  config.embed_fn_config.model_config.window_size_s = 5.0\n",
        "  config.embed_fn_config.model_config.hop_size_s = 5.0\n",
        "  config.embed_fn_config.model_config.sample_rate = 32000\n",
        "elif model_choice == 'birdnet':\n",
        "  config.embed_fn_config.model_config.window_size_s = 3.0\n",
        "  config.embed_fn_config.model_config.hop_size_s = 3.0\n",
        "  config.embed_fn_config.model_config.sample_rate = 16000\n",
        "\n",
        "# Only write embeddings to reduce size.\n",
        "config.embed_fn_config.write_embeddings = True\n",
        "config.embed_fn_config.write_logits = False\n",
        "config.embed_fn_config.write_separated_audio = False\n",
        "config.embed_fn_config.write_raw_audio = False\n",
        "\n",
        "\n",
        "# Embedding windows are broken up into groups, typically one minute in length.\n",
        "# This lets us limit input size to the model, track progres and\n",
        "# recover from failures more easily.\n",
        "config.shard_len_s = 60  #@param\n",
        "config.num_shards_per_file = 1  #@param\n",
        "\n",
        "# Number of parent directories to include in the filename.\n",
        "config.embed_fn_config.file_id_depth = 1\n",
        "\n",
        "# Number of TF Record files to create.\n",
        "config.tf_record_shards = 10  #@param\n",
        "\n",
        "# Speech filter threshold for YamNet.\n",
        "# Set to a value between 0 and 1, or -1 to disable.\n",
        "config.embed_fn_config.speech_filter_threshold = -1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOFaUEbHNash"
      },
      "outputs": [],
      "source": [
        "#@title Set up. { vertical-output: true }\n",
        "\n",
        "# Create output directory and write the configuration.\n",
        "output_dir = epath.Path(config.output_dir)\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "embed_lib.maybe_write_config(config, output_dir)\n",
        "\n",
        "# Create SourceInfos.\n",
        "source_infos = embed_lib.create_source_infos(\n",
        "    config.source_file_patterns,\n",
        "    config.num_shards_per_file,\n",
        "    config.shard_len_s)\n",
        "print(f'Found {len(source_infos)} source infos.')\n",
        "\n",
        "# Set up the embedding function, including loading models.\n",
        "embed_fn = embed_lib.EmbedFn(**config.embed_fn_config)\n",
        "print('\\n\\nLoading model(s)...')\n",
        "embed_fn.setup()\n",
        "\n",
        "print('\\n\\nTest-run of model...')\n",
        "# We run the test twice - the first run optimizes the execution, and\n",
        "# subsequent runs will be full-speed.\n",
        "window_size_s = config.embed_fn_config.model_config.window_size_s\n",
        "sr = config.embed_fn_config.model_config.sample_rate\n",
        "z = np.zeros([int(sr * window_size_s)])\n",
        "embed_fn.embedding_model.embed(z)\n",
        "print('Setup complete!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAhkOvgKagGP"
      },
      "outputs": [],
      "source": [
        "#@title Run embedding. (safe) { vertical-output: true }\n",
        "\n",
        "# Loads audio files one-by-one using methods which will tend not to fail\n",
        "# if the target files have minor problems (eg, wrong length metadata).\n",
        "\n",
        "embed_fn.min_audio_s = 1.0\n",
        "record_file = (output_dir / 'embeddings.tfrecord').as_posix()\n",
        "succ, fail = 0, 0\n",
        "with tf_examples.EmbeddingsTFRecordMultiWriter(\n",
        "    output_dir=output_dir, num_files=config.tf_record_shards) as file_writer:\n",
        "  for source_info in tqdm.tqdm(source_infos):\n",
        "    examples = embed_fn.process(source_info=source_info)\n",
        "    if examples is None:\n",
        "      fail += 1\n",
        "      continue\n",
        "    for example in examples:\n",
        "      file_writer.write(example.SerializeToString())\n",
        "    succ += 1\n",
        "  file_writer.flush()\n",
        "print(f'\\n\\nSuccessfully processed {succ} source_infos, failed {fail} times.')\n",
        "\n",
        "fns = [fn for fn in output_dir.glob('embeddings-*')]\n",
        "ds = tf.data.TFRecordDataset(fns)\n",
        "parser = tf_examples.get_example_parser()\n",
        "ds = ds.map(parser)\n",
        "for ex in ds.as_numpy_iterator():\n",
        "  print(ex['filename'])\n",
        "  print(ex['embedding'].shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JbRna2tnGj5"
      },
      "outputs": [],
      "source": [
        "#@title Run embedding. (fast) { vertical-output: true }\n",
        "\n",
        "# Uses multiple threads to load audio before embedding.\n",
        "# This tends to be faster, but can fail if any audio files are corrupt.\n",
        "\n",
        "embed_fn.min_audio_s = 1.0\n",
        "record_file = (output_dir / 'embeddings.tfrecord').as_posix()\n",
        "succ, fail = 0, 0\n",
        "\n",
        "audio_iterator = audio_utils.multi_load_audio_window(\n",
        "    filepaths=[s.filepath for s in source_infos],\n",
        "    offsets=[s.shard_num * s.shard_len_s for s in source_infos],\n",
        "    sample_rate=config.embed_fn_config.model_config.sample_rate,\n",
        "    window_size_s=config.shard_len_s,\n",
        ")\n",
        "with tf_examples.EmbeddingsTFRecordMultiWriter(\n",
        "    output_dir=output_dir, num_files=config.tf_record_shards) as file_writer:\n",
        "  for source_info, audio in tqdm.tqdm(\n",
        "      zip(source_infos, audio_iterator), total=len(source_infos)):\n",
        "    file_id = source_info.file_id(config.embed_fn_config.file_id_depth)\n",
        "    offset_s = source_info.shard_num * source_info.shard_len_s\n",
        "    example = embed_fn.audio_to_example(file_id, offset_s, audio)\n",
        "    if example is None:\n",
        "      fail += 1\n",
        "      continue\n",
        "    file_writer.write(example.SerializeToString())\n",
        "    succ += 1\n",
        "  file_writer.flush()\n",
        "print(f'\\n\\nSuccessfully processed {succ} source_infos, failed {fail} times.')\n",
        "\n",
        "fns = [fn for fn in output_dir.glob('embeddings-*')]\n",
        "ds = tf.data.TFRecordDataset(fns)\n",
        "parser = tf_examples.get_example_parser()\n",
        "ds = ds.map(parser)\n",
        "for ex in ds.as_numpy_iterator():\n",
        "  print(ex['filename'])\n",
        "  print(ex['embedding'].shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yi4nL7JtNvI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1IDQF847QIc7eZmxpJmX8QPcfe9bmoKwe",
          "timestamp": 1689281193726
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
